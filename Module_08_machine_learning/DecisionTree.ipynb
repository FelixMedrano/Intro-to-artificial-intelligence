{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTree",
      "provenance": [],
      "authorship_tag": "ABX9TyNwlhEvf3Yw8dpijBVWdOp0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelixMedrano/Intro-to-artificial-intelligence/blob/main/Module_08_machine_learning/DecisionTree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZGIBWEVzthh"
      },
      "source": [
        "A runable version of this can be found at\n",
        "\n",
        "https://colab.research.google.com/drive/10xvwLbsKciqTkbYkeO4pvWPQVQTpJ_q7?usp=sharing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHlw_XufzRnt",
        "outputId": "d66e500d-3a6f-4973-d302-ba80e45dbe91"
      },
      "source": [
        "# Decision Trees\n",
        "# Decision trees are structures that describe a series of decisions that are made to find a solution to a problem.\n",
        "# If weâ€™re deciding whether or not to wear shorts for the day, we might make a series of decisions to inform the\n",
        "# outcome. Will it be cold during the day? If not, will we be out late in the evening when it does get cold?\n",
        "# We might decide to wear shorts on a warm day, but not if we will be out when it gets cold.\n",
        "# In building a decision tree, all possible questions will be tested to determine which one is the best question to\n",
        "# ask at a specific point in the decision tree. To test a question, the concept of entropy is used. Entropy is the\n",
        "# uncertainty of the dataset.\n",
        "\n",
        "#This program is by Rishal Hurbans for Grokkings Ai Algorithms textbook. The git repo can be found at\n",
        "#https://github.com/rishal-hurbans/Grokking-Artificial-Intelligence-Algorithms/tree/master/ch08-machine_learning/decision_trees\n",
        "\n",
        "\n",
        "# The data used for learning\n",
        "feature_names = ['carat', 'price', 'cut']\n",
        "feature_examples = [[0.21, 327, 'Average'],\n",
        "                    [0.39, 897, 'Perfect'],\n",
        "                    [0.50, 1122, 'Perfect'],\n",
        "                    [0.76, 907, 'Average'],\n",
        "                    [0.87, 2757, 'Average'],\n",
        "                    [0.98, 2865, 'Average'],\n",
        "                    [1.13, 3045, 'Perfect'],\n",
        "                    [1.34, 3914, 'Perfect'],\n",
        "                    [1.67, 4849, 'Perfect'],\n",
        "                    [1.81, 5688, 'Perfect']]\n",
        "\n",
        "\n",
        "# The Question class defines a feature and value that it should satisfy\n",
        "class Question:\n",
        "\n",
        "    def __init__(self, feature, value):\n",
        "        self.feature = feature\n",
        "        self.value = value\n",
        "\n",
        "    def filter(self, example):\n",
        "        value = example[self.feature]\n",
        "        return value >= self.value\n",
        "\n",
        "    def to_string(self):\n",
        "        return 'Is ' + feature_names[self.feature] + ' >= ' + str(self.value) + '?'\n",
        "\n",
        "\n",
        "# The ExamplesNode class defines a node in the tree that contains classified examples\n",
        "class ExamplesNode:\n",
        "    def __init__(self, examples):\n",
        "        self.examples = find_unique_label_counts(examples)\n",
        "\n",
        "\n",
        "# The DecisionNode class defines a node in the tree that contains a question, and two branches\n",
        "class DecisionNode:\n",
        "    def __init__(self, question, branch_true, branch_false):\n",
        "        self.question = question\n",
        "        self.branch_true = branch_true\n",
        "        self.branch_false = branch_false\n",
        "\n",
        "\n",
        "# Count the unique classes and their counts from a list of examples\n",
        "def find_unique_label_counts(examples):\n",
        "    class_count = {}\n",
        "    for example in examples:\n",
        "        label = example[-1]\n",
        "        if label not in class_count:\n",
        "            class_count[label] = 0\n",
        "        class_count[label] += 1\n",
        "    return class_count\n",
        "\n",
        "\n",
        "# Split a list of examples based on a question being asked\n",
        "def split_examples(examples, question):\n",
        "    examples_true = []\n",
        "    examples_false = []\n",
        "    for example in examples:\n",
        "        if question.filter(example):\n",
        "            examples_true.append(example)\n",
        "        else:\n",
        "            examples_false.append(example)\n",
        "    return examples_true, examples_false\n",
        "\n",
        "\n",
        "# Calculate the Gini Index based on a list of examples\n",
        "def calculate_gini(examples):\n",
        "    label_counts = find_unique_label_counts(examples)\n",
        "    uncertainty = 1\n",
        "    for label in label_counts:\n",
        "        probability_of_label = label_counts[label] / float(len(examples))\n",
        "        uncertainty -= probability_of_label ** 2\n",
        "    return uncertainty\n",
        "\n",
        "\n",
        "# Calculate the information gain based on the left gini, right gini, and current uncertainty\n",
        "def calculate_information_gain(left_gini, right_gini, current_uncertainty):\n",
        "    total = len(left_gini) + len(right_gini)\n",
        "    gini_left = calculate_gini(left_gini)\n",
        "    entropy_left = len(left_gini) / total * gini_left\n",
        "    gini_right = calculate_gini(right_gini)\n",
        "    entropy_right = len(right_gini) / total * gini_right\n",
        "    uncertainty_after = entropy_left + entropy_right\n",
        "    information_gain = current_uncertainty - uncertainty_after\n",
        "    return information_gain\n",
        "\n",
        "\n",
        "# Fine the best split for a list of examples based on its features\n",
        "def find_best_split(examples, number_of_features):\n",
        "    best_gain = 0\n",
        "    best_question = None\n",
        "    current_uncertainty = calculate_gini(examples)\n",
        "    for feature_index in range(number_of_features):\n",
        "        values = set([example[feature_index] for example in examples])\n",
        "        for value in values:\n",
        "            question = Question(feature_index, value)\n",
        "            examples_true, examples_false = split_examples(examples, question)\n",
        "            if len(examples_true) != 0 or len(examples_false) != 0:\n",
        "                gain = calculate_information_gain(examples_true, examples_false, current_uncertainty)\n",
        "                if gain >= best_gain:\n",
        "                    best_gain, best_question = gain, question\n",
        "    return best_gain, best_question\n",
        "\n",
        "\n",
        "# Build the decision tree\n",
        "def build_tree(examples):\n",
        "    gain, question = find_best_split(examples, len(examples[0]) - 1)\n",
        "    if gain == 0:\n",
        "        return ExamplesNode(examples)\n",
        "    print('Best question : ', question.to_string(), '\\t', 'Info gain: ', \"{0:.3f}\".format(gain))\n",
        "    examples_true, examples_false = split_examples(examples, question)\n",
        "    branch_true = build_tree(examples_true)\n",
        "    branch_false = build_tree(examples_false)\n",
        "    return DecisionNode(question, branch_true, branch_false)\n",
        "\n",
        "\n",
        "def print_tree(node, indentation=''):\n",
        "    # The examples in the current ExamplesNode\n",
        "    if isinstance(node, ExamplesNode):\n",
        "        print(indentation + 'Examples', node.examples)\n",
        "        return\n",
        "    # The question for the current DecisionNode\n",
        "    print(indentation + str(node.question.to_string()))\n",
        "    # Find the 'True' examples for the current DecisionNode recursively\n",
        "    print(indentation + '---> True:')\n",
        "    print_tree(node.branch_true, indentation + '\\t')\n",
        "    # Find the 'False' examples for the current DecisionNode recursively\n",
        "    print(indentation + '---> False:')\n",
        "    print_tree(node.branch_false, indentation + '\\t')\n",
        "\n",
        "\n",
        "tree = build_tree(feature_examples)\n",
        "print_tree(tree)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best question :  Is price >= 3045? \t Info gain:  0.213\n",
            "Best question :  Is carat >= 0.76? \t Info gain:  0.222\n",
            "Best question :  Is price >= 897? \t Info gain:  0.444\n",
            "Is price >= 3045?\n",
            "---> True:\n",
            "\tExamples {'Perfect': 4}\n",
            "---> False:\n",
            "\tIs carat >= 0.76?\n",
            "\t---> True:\n",
            "\t\tExamples {'Average': 3}\n",
            "\t---> False:\n",
            "\t\tIs price >= 897?\n",
            "\t\t---> True:\n",
            "\t\t\tExamples {'Perfect': 2}\n",
            "\t\t---> False:\n",
            "\t\t\tExamples {'Average': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}