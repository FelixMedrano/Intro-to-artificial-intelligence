{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron",
      "provenance": [],
      "authorship_tag": "ABX9TyMuu6pkVwywTtQTLBfVOW/r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelixMedrano/Intro-to-artificial-intelligence/blob/main/Module_09_artificial_neural_networks/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTjc93Kl1lME"
      },
      "source": [
        "his program is by Rishal Hurbans for Grokkings Ai Algorithms textbook. The git repo can be found at\n",
        "\n",
        "https://github.com/rishal-hurbans/Grokking-Artificial-Intelligence-Algorithms/tree/master/ch09-artificial_neural_networks\n",
        "\n",
        "A runable version of this can be found at\n",
        "\n",
        "https://colab.research.google.com/drive/10HsOeqMtEpArZFTDypjGuhXcBWPnbe8K?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ams3mMae1eMV",
        "outputId": "8fa183e1-0c94-4b33-e24e-8ea566f5b3c0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# The Perceptron\n",
        "# The neuron is the fundamental concept that makes up the brain and nervous systems.\n",
        "# It accepts many inputs from other neurons, processes those inputs, and transfers the result to other “connected”\n",
        "# neurons. Artificial neural networks are based on the fundamental concept of the Perceptron. The Perceptron is a\n",
        "# logical representation of a single biological neuron.\n",
        "\n",
        "# Features\n",
        "# Smoking, Obesity, Exercise\n",
        "dataset = np.array([[0, 1, 0],\n",
        "                    [0, 0, 1],\n",
        "                    [1, 0, 0],\n",
        "                    [1, 1, 0],\n",
        "                    [1, 1, 0],\n",
        "                    [1, 0, 1],\n",
        "                    [0, 1, 0],\n",
        "                    [1, 1, 1]])\n",
        "dataset_labels = np.array([[1, 0, 0, 1, 1, 0, 0, 1]])\n",
        "dataset_labels = dataset_labels.reshape(8, 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "weights = np.random.rand(3, 1)\n",
        "bias = 1  # np.random.rand(1)\n",
        "learning_rate = 0.05\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x)*(1-sigmoid(x))\n",
        "\n",
        "\n",
        "for epoch in range(10000):\n",
        "    # Multiply every input with it's respective weight and sum the outputs\n",
        "    weight_and_sum_results = np.dot(dataset, weights) + bias\n",
        "    # Apply the sigmoid activation function to all the input sums\n",
        "    activation_results = sigmoid(weight_and_sum_results)\n",
        "    # Determine error for each data row\n",
        "    error = activation_results - dataset_labels\n",
        "    # Find slope of the predicated results using derivatives\n",
        "    predicted_results_derivative = sigmoid_derivative(activation_results)\n",
        "    # Find amount to adjust weights by\n",
        "    z_delta = error * predicted_results_derivative\n",
        "    # Transpose array to work with consistent shaped matrices\n",
        "    inputs = dataset.transpose()\n",
        "    # Update weights using gradient descent\n",
        "    weights -= learning_rate * np.dot(inputs, z_delta)\n",
        "    # Update bias\n",
        "    for num in z_delta:\n",
        "        bias -= learning_rate * num\n",
        "\n",
        "\n",
        "# Smoker, obese, no exercise\n",
        "single_point = np.array([1, 0, 0])\n",
        "result = sigmoid(np.dot(single_point, weights) + bias)\n",
        "print('Smoker, not obese, no exercise')\n",
        "print(result)\n",
        "\n",
        "# Non smoker, obese, no exercise\n",
        "single_point = np.array([0, 1, 0])\n",
        "result = sigmoid(np.dot(single_point, weights) + bias)\n",
        "print('Non smoker, obese, no exercise')\n",
        "print(result)\n",
        "\n",
        "# Non smoker, not obese, exercise\n",
        "single_point = np.array([0, 0, 1])\n",
        "result = sigmoid(np.dot(single_point, weights) + bias)\n",
        "print('Non smoker, not obese, does exercise')\n",
        "print(result)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smoker, not obese, no exercise\n",
            "[0.01778236]\n",
            "Non smoker, obese, no exercise\n",
            "[0.5132903]\n",
            "Non smoker, not obese, does exercise\n",
            "[0.00026388]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}